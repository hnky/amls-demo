{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMLS Estimator for Marge vs Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.69\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Experiment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import DataTransferStep, PythonScriptStep, EstimatorStep\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.dnn import TensorFlow\n",
    "import os\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/431dbae5-40ca-438a-8daf-77d7d5580b41/resourceGroups/AMLS-Demo-RG/providers/Microsoft.MachineLearningServices/workspaces/AMLS-Workspace',\n",
       " 'name': 'AMLS-Workspace',\n",
       " 'location': 'westeurope',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'tags': {},\n",
       " 'workspaceid': '7762f3db-1959-4f1c-aac2-b8d3e035f52b',\n",
       " 'description': '',\n",
       " 'friendlyName': '',\n",
       " 'creationTime': '2019-09-10T08:07:46.7167284+00:00',\n",
       " 'containerRegistry': '/subscriptions/431dbae5-40ca-438a-8daf-77d7d5580b41/resourceGroups/AMLS-Demo-RG/providers/Microsoft.ContainerRegistry/registries/amlsworkspac2bb6e513',\n",
       " 'keyVault': '/subscriptions/431dbae5-40ca-438a-8daf-77d7d5580b41/resourcegroups/amls-demo-rg/providers/microsoft.keyvault/vaults/amlsworkspace3533516247',\n",
       " 'applicationInsights': '/subscriptions/431dbae5-40ca-438a-8daf-77d7d5580b41/resourcegroups/amls-demo-rg/providers/microsoft.insights/components/amlsworkspace6001352158',\n",
       " 'identityPrincipalId': '89da5ddd-ca21-4e89-a603-e4373100ffef',\n",
       " 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/431dbae5-40ca-438a-8daf-77d7d5580b41/resourcegroups/amls-demo-rg/providers/microsoft.storage/storageaccounts/amlsworkspace7862806160'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current node count:  1\n",
      "VM Size:  STANDARD_NV6\n",
      "Name: NV6AICluster\n"
     ]
    }
   ],
   "source": [
    "clusterName = \"NV6AICluster\"\n",
    "computeCluster = ComputeTarget(workspace=ws, name=clusterName)\n",
    "\n",
    "\n",
    "# Get some details from your cluster\n",
    "status = computeCluster.get_status()\n",
    "print(\"Current node count: \",status.current_node_count)\n",
    "print(\"VM Size: \",status.vm_size)\n",
    "print(\"Name:\",computeCluster.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ds = Datastore.get(ws, 'SimpsonDataStore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpsons-AI\n"
     ]
    }
   ],
   "source": [
    "ExperimentName = \"Simpsons-AI\"\n",
    "\n",
    "exp = Experiment(workspace=ws, name=ExperimentName)\n",
    "print(exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = \"./trainingscripts\"\n",
    "script_params = {\n",
    "    \"--data-folder\": source_ds.as_mount(),\n",
    "    \"--pic-size\":64,\n",
    "    \"--batch-size\":32,\n",
    "    \"--epochs\":10\n",
    "}\n",
    "\n",
    "estimator = TensorFlow (\n",
    "     source_directory = script_folder,\n",
    "     script_params = script_params,\n",
    "     compute_target = computeCluster,\n",
    "     entry_script = \"train.py\", \n",
    "     use_gpu = True,\n",
    "     use_docker = True,\n",
    "     conda_packages=[\"keras==2.2.2\",\"opencv==3.4.2\",\"scikit-learn\"],\n",
    "     framework_version=\"1.10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a883fcb67ad04b2f8696945c8020526e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = exp.submit(estimator)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', timeout())': /azureml/LocalUpload/191017T070523-aa6ccdc1/SimpsonsAI-NDC.tar.gz?sv=2018-11-09&sr=b&sig=YP2x3R5l6Jg16GH3WZ8MxuMafnBW3zIDS4Ajqzdx%2Bfg%3D&st=2019-10-17T04%3A55%3A23Z&se=2019-10-18T05%3A05%3A23Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNRFF4T1RRek1EUSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model SimpsonsAI-NDC\n"
     ]
    }
   ],
   "source": [
    "model_file_h5 = \"outputs/simple_model.h5\"\n",
    "model_file_json = \"outputs/simple_model.json\"\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "run.download_file(name=model_file_h5, output_file_path=\"outputs/simple_model.h5\")\n",
    "run.download_file(name=model_file_json, output_file_path=\"outputs/simple_model.json\")\n",
    "\n",
    "model = Model.register(ws, \n",
    "               model_name=\"SimpsonsAI-NDC\", \n",
    "               model_path=\"outputs\", \n",
    "               tags = {\"conference\": \"NDC SYDNEY\"}, \n",
    "               description=\"Simpson classification model created at NDC Sydney\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name SimpsonsAI-NDC\n",
      "Version 2\n"
     ]
    }
   ],
   "source": [
    "model = Model(ws, 'SimpsonsAI-NDC')\n",
    "\n",
    "print(\"Name\",model.name)\n",
    "print(\"Version\",model.version)\n",
    "\n",
    "output_path = \".\"\n",
    "#os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "result = model.download(target_dir=output_path, exist_ok=True)\n",
    "\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model localy\n",
    "\n",
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "\n",
    "### Settings\n",
    "json_file_path = \"outputs/simple_model.json\"\n",
    "model_file_path = \"outputs/simple_model.h5\"\n",
    "test_images_directory = \"testset-marge-vs-homer\"\n",
    "pic_size = 64\n",
    "\n",
    "### characters\n",
    "map_characters = {0:\"marge_simpson\", 1: \"homer_simpson\" }\n",
    "\n",
    "### Load the model\n",
    "json_file = open(json_file_path, \"r\") \n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(model_file_path)  \n",
    "\n",
    "### Prediction method => image preprocessing + prediction\n",
    "def predict_image(img):\n",
    "    image = cv2.imread(img)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(image, (pic_size,pic_size))\n",
    "    data = pic.reshape(1, pic_size, pic_size,3)\n",
    "    predicted_labels = loaded_model.predict(data)[0]\n",
    "    return predicted_labels, img\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "F = plt.figure(1, (20,20))\n",
    "grid = AxesGrid(F, 111, nrows_ncols=(3, 3), axes_pad=0, label_mode=\"1\")\n",
    "\n",
    "testimages = os.listdir(test_images_directory)\n",
    "random.shuffle(testimages)\n",
    "\n",
    "i = 0\n",
    "for img_name in testimages[0:9]:\n",
    "    a, img = predict_image(os.path.join(test_images_directory,img_name))\n",
    "\n",
    "    text = sorted([\"{:s} : {:.1f}%\".format(map_characters[k].split(\"_\")[0].title(), 100*v) for k,v in enumerate(a)], \n",
    "       key=lambda x:float(x.split(\":\")[1].split(\"%\")[0]), reverse=True)[:3]\n",
    "    img = cv2.resize(img, (352, 352))\n",
    "    cv2.rectangle(img, (0,260),(215,352),(255,255,255), -1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    for k, t in enumerate(text):\n",
    "        cv2.putText(img, t,(10, 300+k*25), font, 0.75,(0,0,0),2,cv2.LINE_AA)\n",
    "    grid[i].imshow(img)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
